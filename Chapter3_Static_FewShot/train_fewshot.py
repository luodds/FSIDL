import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from tqdm import tqdm
import numpy as np

# è·¯å¾„ Hack
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from Chapter3_Static_FewShot.data_loader import InMemoryDataset, get_supcon_transforms
from Chapter3_Static_FewShot.models.prompt_learner import VisualPromptResNet
from utils.few_shot_sampler import get_few_shot_indices
# å¼•å…¥ç»˜å›¾å·¥å…·
from utils.visualizer import plot_training_curves, plot_confusion_matrix, plot_tsne

class DatasetWrapper(torch.utils.data.Dataset):
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform
    def __getitem__(self, index):
        x, y = self.subset[index]
        if isinstance(x, torch.Tensor):
            from PIL import Image
            x = Image.fromarray(x.numpy(), mode='L')
        if self.transform:
            x = self.transform(x)
        return x, y
    def __len__(self):
        return len(self.subset)

def train_few_shot():
    # --- é…ç½® ---
    N_SHOTS = 5
    EPOCHS = 30
    BATCH_SIZE = 64
    LR = 0.01
    DEVICE = 'cuda'
    SAVE_DIR = './Chapter3_Static_FewShot/results_visual' # å›¾ç‰‡ä¿å­˜è·¯å¾„
    
    os.makedirs(SAVE_DIR, exist_ok=True)
    
    DATA_PATH = './data/5G-NIDD/processed_images'
    PRETRAINED_PATH = './Chapter3_Static_FewShot/saved_models/supcon_epoch_50.pth'
    cache_file = './data/5G-NIDD/5G_NIDD_tensor_cache.pt'

    # 1. åŠ è½½æ•°æ®
    full_dataset = InMemoryDataset(DATA_PATH, cache_path=cache_file)
    class_names = full_dataset.classes # è·å–ç±»åˆ«ååˆ—è¡¨

    # 2. åˆ’åˆ†
    train_idx, test_idx = get_few_shot_indices(full_dataset, n_shots=N_SHOTS)
    
    train_set = DatasetWrapper(Subset(full_dataset, train_idx), transform=get_supcon_transforms(mode='train'))
    test_set = DatasetWrapper(Subset(full_dataset, test_idx), transform=get_supcon_transforms(mode='test'))
    
    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_set, batch_size=2048, shuffle=False, num_workers=0)

    # 3. æ¨¡å‹
    model = VisualPromptResNet(pretrained_path=PRETRAINED_PATH, num_classes=len(class_names))
    model = model.to(DEVICE)
    
    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), 
                          lr=LR, momentum=0.9, weight_decay=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    # --- è®°å½•æ•°æ®ç”¨äºç»˜å›¾ ---
    history = {'train_loss': [], 'train_acc': [], 'test_acc': []}

    # # --- è®­ç»ƒå¾ªç¯ ---
    # best_acc = 0.0
    # print(f"[Info] å¼€å§‹è®­ç»ƒ... ç»“æœå°†ä¿å­˜è‡³ {SAVE_DIR}")

    # for epoch in range(1, EPOCHS + 1):
    #     model.train()
    #     total_loss = 0; correct = 0; total = 0
        
    #     for images, labels in train_loader:
    #         images, labels = images.to(DEVICE), labels.to(DEVICE)
    #         optimizer.zero_grad()
    #         outputs = model(images)
    #         loss = criterion(outputs, labels)
    #         loss.backward()
    #         optimizer.step()
            
    #         total_loss += loss.item()
    #         _, predicted = outputs.max(1)
    #         total += labels.size(0)
    #         correct += predicted.eq(labels).sum().item()
            
    #     train_acc = 100. * correct / total
        
    #     # éªŒè¯
    #     model.eval()
    #     test_correct = 0; test_total = 0
    #     with torch.no_grad():
    #         for images, labels in test_loader:
    #             images, labels = images.to(DEVICE), labels.to(DEVICE)
    #             outputs = model(images)
    #             _, predicted = outputs.max(1)
    #             test_total += labels.size(0)
    #             test_correct += predicted.eq(labels).sum().item()
        
    #     test_acc = 100. * test_correct / test_total
        
    #     # è®°å½•å†å²
    #     history['train_loss'].append(total_loss)
    #     history['train_acc'].append(train_acc)
    #     history['test_acc'].append(test_acc)

    #     print(f"Epoch {epoch}: Train Loss={total_loss:.4f}, Test Acc={test_acc:.2f}%")
        
    #     if test_acc > best_acc:
    #         best_acc = test_acc
    #         torch.save(model.state_dict(), os.path.join(SAVE_DIR, 'best_fewshot_model.pth'))

    # print(f"[Done] è®­ç»ƒç»“æŸã€‚æœ€é«˜å‡†ç¡®ç‡: {best_acc:.2f}%")

    # ==========================================
    #              å¯è§†åŒ–é˜¶æ®µ
    # ==========================================
    print("\n[Visual] å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

    # 1. ç»˜åˆ¶è®­ç»ƒæ›²çº¿ (ä¿æŒä¸å˜)
    plot_training_curves(history['train_loss'], history['train_acc'], history['test_acc'], SAVE_DIR)

    # 2. å‡è¡¡é‡‡æ ·é€»è¾‘ (ä¸“é—¨ä¿®å¤ t-SNE åªæœ‰ Benign çš„é—®é¢˜)
    print("[Visual] æ­£åœ¨è¿›è¡Œã€å‡è¡¡é‡‡æ ·ã€‘ä»¥ç”Ÿæˆé«˜è´¨é‡ t-SNE...")
    
    # é‡æ–°åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load(os.path.join(SAVE_DIR, 'best_fewshot_model.pth')))
    model.eval()
    
    # --- å‡è¡¡é‡‡æ ·é…ç½® ---
    SAMPLES_PER_CLASS = 200  # æ¯ä¸ªç±»åˆ«åªå– 200 ä¸ªæ ·æœ¬ç”»å›¾ï¼Œä¿è¯å›¾åƒæ¸…æ™°ä¸”è®¡ç®—å¿«
    num_classes = len(class_names)
    class_counts = {i: 0 for i in range(num_classes)} # è®¡æ•°å™¨: {0: 0, 1: 0, ...}
    
    tsne_features = []
    tsne_labels = []
    
    # åŒæ—¶ä¹Ÿæ”¶é›†å…¨é‡é¢„æµ‹ç”¨äºæ··æ·†çŸ©é˜µ
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        # éå†æµ‹è¯•é›†
        for images, labels in tqdm(test_loader, desc="Balanced Sampling"):
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            
            # 1. è·å–åˆ†ç±»ç»“æœ (ç”¨äºæ··æ·†çŸ©é˜µ - å…¨é‡)
            outputs = model(images)
            _, predicted = outputs.max(1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            # 2. è·å–ç‰¹å¾ (ç”¨äº t-SNE - å‡è¡¡é‡‡æ ·)
            # æ£€æŸ¥å½“å‰ batch é‡Œæœ‰æ²¡æœ‰æˆ‘ä»¬éœ€è¦å¡«è¡¥åé¢çš„ç±»åˆ«
            # å¦‚æœæ‰€æœ‰ç±»åˆ«éƒ½å‡‘å¤Ÿäº† SAMPLES_PER_CLASSï¼Œå°±è·³è¿‡ç‰¹å¾æå–ï¼ŒèŠ‚çœæ—¶é—´
            if all(c >= SAMPLES_PER_CLASS for c in class_counts.values()):
                continue

            # æå–ç‰¹å¾
            x_prompted = images + model.prompt
            feats = model.backbone.extract_features(x_prompted)
            
            # é€ä¸ªæ ·æœ¬åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿ç•™
            feats_np = feats.cpu().numpy()
            labels_np = labels.cpu().numpy()
            
            for i in range(len(labels_np)):
                label = int(labels_np[i])
                # å¦‚æœè¯¥ç±»åˆ«çš„åé¢è¿˜æ²¡æ»¡ï¼Œå°±æ”¶å½•
                if class_counts[label] < SAMPLES_PER_CLASS:
                    tsne_features.append(feats_np[i])
                    tsne_labels.append(labels_np[i])
                    class_counts[label] += 1

    print(f"[Visual] é‡‡æ ·ç»Ÿè®¡: {class_counts}")

    # 3. ç»˜åˆ¶æ··æ·†çŸ©é˜µ (å…¨é‡)
    plot_confusion_matrix(all_labels, all_preds, class_names, SAVE_DIR)

    # 4. ç»˜åˆ¶ t-SNE (å‡è¡¡æ ·æœ¬)
    if len(tsne_features) > 0:
        tsne_features = np.array(tsne_features)
        tsne_labels = np.array(tsne_labels)
        print(f"[Visual] t-SNE è¾“å…¥æ•°æ®å½¢çŠ¶: {tsne_features.shape}")
        
        plot_tsne(tsne_features, tsne_labels, class_names, SAVE_DIR, 
                  title=f"t-SNE Visualization ({SAMPLES_PER_CLASS} samples/class)")
    else:
        print("[Error] æœªæ”¶é›†åˆ° t-SNE æ•°æ®ï¼Œè¯·æ£€æŸ¥æµ‹è¯•é›†ã€‚")
    
    print(f"\nğŸ‰ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {os.path.abspath(SAVE_DIR)}")

if __name__ == '__main__':
    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
    train_few_shot()